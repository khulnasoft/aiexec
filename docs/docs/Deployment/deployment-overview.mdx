---
title: Aiexec deployment overview
slug: /deployment-overview
---

This section includes the different ways to bring your locally-built flows to the world.

* To self-host your local server through an ngrok gateway, see [Deploy a public Aiexec server](/deployment-public-server).
This approach uses [ngrok](https://ngrok.com/docs/getting-started/) to forward traffic and share your local Aiexec server over the internet, without deploying to a cloud provider or exposing your network directly.

* To build and deploy a Aiexec container that includes your flow files, see [Containerize a Aiexec application](develop-application).
This approach bundles your flows and dependencies into a portable, reproducible Docker image for easy deployment across different environments.

* To deploy a Aiexec server on a remote server with Docker and Caddy, see [Deploy Aiexec on a remote server](/deployment-caddyfile).
This approach is good for hosting your own Aiexec instance on a remote server with secure web access, using Docker containers and Caddy as a reverse proxy for HTTPS support.

* To deploy Aiexec on Kubernetes, see [Aiexec Kubernetes architecture and best practices](/deployment-prod-best-practices)
This approach creates production-grade deployments with high availability, scalability, and robust orchestration.

* For cloud provider-specific deployment guides, see your cloud provider's documentation.
The Aiexec documentation provides a few examples, such as [Google Cloud Platform](/deployment-gcp) and [Hugging Face Spaces](/deployment-hugging-face-spaces), to help you get started.